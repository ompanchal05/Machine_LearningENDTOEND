# ğŸ“˜ learn_1.md
## Machine Learning Foundations â€” Learn & Revise

---

## ğŸ“Œ Purpose of This Series

| Item | Description |
|------|-------------|
| Goal | Learn ML once and revise quickly |
| Level | Beginner â†’ Internship Ready |
| Style | Simple English, practical |
| Use | Learning, revision, interviews |

---

## ğŸ§  What is Machine Learning?

| Topic | Explanation |
|------|-------------|
| Machine Learning | Teaching computers to learn from data |
| Input | Past data |
| Output | Predictions / decisions |
| Without ML | Fixed rules |
| With ML | Data-driven learning |

---

## ğŸ“Š Types of Machine Learning

| Type | Meaning | Examples |
|------|--------|----------|
| Supervised Learning | Data with labels | Linear Reg, Logistic Reg, KNN |
| Unsupervised Learning | No labels | KMeans, PCA |
| Semi-Supervised Learning | Few labels | Text & image tasks |
| Reinforcement Learning | Reward-based | Games, Robotics |

---

## ğŸ§© Dataset Basics

### Features vs Target

| Term | Symbol | Meaning |
|------|--------|---------|
| Features | X | Input variables |
| Target | y | Output variable |
| X | Capital | Matrix (many columns) |
| y | Small | Vector (single column) |

Example:
X = [Age, Salary, Experience]
y = [Price]


---

## âœ‚ï¸ Trainâ€“Test Split

| Item | Explanation |
|------|-------------|
| Purpose | Test model on unseen data |
| Training Set | Used to learn patterns |
| Testing Set | Used to evaluate model |
| Common Split | 80% Train / 20% Test |
| Benefit | Avoids overfitting |

---

## â“ Why X is Capital and y is Small?

| Symbol | Reason |
|------|--------|
| X | Represents feature matrix |
| y | Represents output vector |
| Convention | From mathematics |

Example:
X shape â†’ (100, 5)
y shape â†’ (100,)

---

## ğŸ“ Feature Scaling

| Item | Explanation |
|------|-------------|
| Meaning | Make all features same scale |
| Why | Distance & gradient sensitive |
| Without Scaling | Poor learning |
| Common Tool | StandardScaler |

### Models That Need Scaling

| Model | Scaling Needed |
|------|---------------|
| KNN | Yes |
| SVM | Yes |
| Logistic Regression | Yes |
| Gradient Descent | Yes |
| Tree Models | No |

---

## ğŸ“‰ Loss Function

| Item | Explanation |
|------|-------------|
| Loss | Measures model error |
| Goal | Minimize loss |
| Regression Loss | MSE |
| Classification Loss | Log Loss |

---

## ğŸ” Gradient Descent

| Item | Explanation |
|------|-------------|
| Type | Optimization algorithm |
| Purpose | Minimize loss |
| Method | Step-by-step weight update |
| Used In | Linear, Logistic, Neural Nets |

---

## âš–ï¸ Bias vs Variance

| Concept | Meaning |
|--------|---------|
| Bias | Model too simple |
| Variance | Model too complex |
| Underfitting | High bias |
| Overfitting | High variance |
| Goal | Balance both |

---

## ğŸ§ª Model Evaluation Metrics

### Regression Metrics

| Metric | Meaning |
|--------|--------|
| MSE | Mean Squared Error |
| RMSE | Root Mean Squared Error |
| RÂ² | Explained variance |

### Classification Metrics

| Metric | Meaning |
|--------|--------|
| Accuracy | Correct predictions |
| Precision | Correct positive predictions |
| Recall | Found actual positives |
| Confusion Matrix | Error breakdown |

---

## ğŸ§  One-Line Interview Revision

| Concept | One Line |
|--------|----------|
| Train-test split | Tests on unseen data |
| Scaling | Needed for distance-based models |
| Gradient Descent | Minimizes loss |
| Overfitting | Memorization |
| Underfitting | Too simple model |

---

## ğŸ“‚ Learning Series Roadmap

| File | Content |
|------|--------|
| learn_1.md | ML foundations |
| learn_2.md | Regression + Gradient Descent |
| learn_3.md | Classification Algorithms |
| learn_4.md | Trees & Ensembles |
| learn_5.md | Model Tuning & Pipelines |
| learn_6.md | Interview Revision Notes |

---

## âœ… Final Note

| Point | Message |
|------|---------|
| Strategy | Learn â†’ Build â†’ Revise |
| Key | Consistency |
| Outcome | Internship Ready |

---
---
